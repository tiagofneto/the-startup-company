{"transpiled":true,"noir_version":"0.33.0+8ac81b15cd2a3b57493bfbfe444086deac8f3dc8","name":"CompanyRegistry","functions":[{"name":"compute_note_hash_and_optionally_a_nullifier","is_unconstrained":true,"custom_attributes":[],"abi":{"error_types":{},"parameters":[{"name":"contract_address","type":{"fields":[{"name":"inner","type":{"kind":"field"}}],"kind":"struct","path":"protocol_types::address::aztec_address::AztecAddress"},"visibility":"private"},{"name":"nonce","type":{"kind":"field"},"visibility":"private"},{"name":"storage_slot","type":{"kind":"field"},"visibility":"private"},{"name":"note_type_id","type":{"kind":"field"},"visibility":"private"},{"name":"compute_nullifier","type":{"kind":"boolean"},"visibility":"private"},{"name":"serialized_note","type":{"kind":"array","length":0,"type":{"kind":"field"}},"visibility":"private"}],"return_type":{"abi_type":{"kind":"array","length":4,"type":{"kind":"field"}},"visibility":"public"}},"bytecode":"H4sIAAAAAAAA/9VWzU7CQBDeBQoVW4h61jR68VgSSDiS+PsAvgDBJnIBQ6vPL2Pnk8+FcHE3sZtsZjo7P9/Mzu7WmnrE22mVj5R2zf6Azkxp/rcx8ugrD4nTNgRnqyE42w3B2fGI0x7AKbSjvJw7OXM9U5/HvUU2lo1u07o54sg6QWVcE3+r9OVtWWaL9arazBdV9rouymy1rrKPssjeN8vPeVXId1H+OJoojRUQg575qdoodhL35ns6XojvfhjcE/F9GsZ3Lpt7p4UBfsSSfXjSNVCrMzF10xiyT8yuce5JhoZ7IBlehEeS9czvWLHOAPs1Fb8nIXxv+yyhGgJ/QjzWJN8r0osC5toNk+s42B7l9S2HPYrUN2J1qW587jy+riPr9IilWJB3iL8kXehBp014ZQzMrt/7R+wix25IOj2yix07fOMuFT8Xyp9v53O804X/UHV07y+ff0C4i5CLpVh9kkPnRumZ2R9cA+MRo/hNKX+f54/vGkMxePDDnlKuSRhM3/cf4gDbkGTcZ6mDE9+tf2R3KB+RDYgHxTlPSYb6D8jvF96XymUuDQAA","debug_symbols":"lZDBCsMgDIbfJWcPXR0VfJUxirZaAhKL2sEQ333ptkOvXkK+5P8uf4XV2WObkXzMoB8VQlxMwUhMtQmwCUPAbb6eYTiHHL75vBs6MReTCmg5KQGOVt7UyL7H4EBPqj0FyFu3MXYbstu49xmN6WUSGhvcvyR/0HLprLz334fDHw==","brillig_names":["compute_note_hash_and_optionally_a_nullifier"]},{"name":"create_company","is_unconstrained":true,"custom_attributes":["aztec(public)"],"abi":{"error_types":{},"parameters":[{"name":"inputs","type":{"fields":[{"name":"calldata_length","type":{"kind":"field"}},{"name":"is_static_call","type":{"kind":"boolean"}}],"kind":"struct","path":"aztec::context::inputs::public_context_inputs::PublicContextInputs"},"visibility":"private"},{"name":"name","type":{"fields":[{"name":"value","type":{"kind":"field"}}],"kind":"struct","path":"compressed_string::field_compressed_string::FieldCompressedString"},"visibility":"private"},{"name":"email","type":{"fields":[{"name":"value","type":{"kind":"field"}}],"kind":"struct","path":"compressed_string::field_compressed_string::FieldCompressedString"},"visibility":"private"},{"name":"director","type":{"fields":[{"name":"value","type":{"kind":"field"}}],"kind":"struct","path":"compressed_string::field_compressed_string::FieldCompressedString"},"visibility":"private"},{"name":"total_shares","type":{"fields":[{"name":"lo","type":{"kind":"field"}},{"name":"hi","type":{"kind":"field"}}],"kind":"struct","path":"std::uint128::U128"},"visibility":"private"}],"return_type":null},"bytecode":"H4sIAAAAAAAC/11Uy27UMBS9fkxiO57EjpOqUj8AKdBWoh7RfSmPLljxCSxYsECCD2CH+AZ2iD0fwAohJNQlfBCc6zQz045kj+/18TnH13ZOSAl5SspcEZ2Qqh06au4Rfg2aIzIXR1Th7zG3F7SMMJBo4ojEktoAS2rDkUZ/SSv0T6hC/5Rq9M/IoH9O9gFWRqZg2SIsfC6KijxlqRpONZlj9oOUVpxSSGlOKSwSpADVC1TP0BO4bbJsOC/9kvdFpEXoOWxLuM7kW0DRvM6kW0y1EtG65TJgeu0mOnOk3NqDV3JadPeJvpKf6DwL7bAsYlmUMYsYiKE80qVorE3hrAxv/f7d+ZFrqQougvqC4qVYcEeFobDMhIEPRVKlXXi4pd3CSRvQ6AivAsjKhX5m6NHSzJBuGHqXAE4aU1Xs04zjyX7G8ZLoMJd6uHpJ/c6VRlYn5k89V3nMZaWisZR1yJTGLMOI1IhJ2Y+MOrhihTXaeKN0APqxCY5EUA1EXlFzS8RqHH9llMVBoN6vwaIHT8oPCehPlCZ6U7x49uIjYGGitzivsPZAvOdTene8qxzjWl8ul12ugi2ecY7eZhktBwYawdRg+ED1zhHQPtRZ1PacAzu/ERU626K3vIOP+zvIZNnOLA8tGiA/Dom3EXIJFWyxYp9pCFmu+AIFiVG1HdXbkQ28suECNAZin/HG9s0N3mRhQjEX5hIr34WWbXPBvlDaNxe4pLjC/vYVnu06Pn2uVuwf0XIb2GmCvEsD6L7RsKPbYIdGNWVD0qzwRSFhNL/zH3jyFfXl+UGldwPKzFt3XYQ1FwO4vlPYsyZ7fo0dMJ3ssmy7jJuIhwjgT7Oa6Bcolakm+rvhb0gl+DNhcLtOy8Cs8T0zRht7iqchjGMvzlhjQfDHWMANA9yG0zWHVQmlqY3j0GAPZqLfUDje0OH14fV/JYtKYygFAAA=","debug_symbols":"7Z1hTxsxDIb/y33mQ5zEic1fmaapbDBVqsoEbNKE+O+7dk163N0SRaXM7vEFWngxj5303sS6ps/dt9ubn9+/rLd394/d9afnbnP/dfW0vt/2z55frrqbh/Vms/7+Zfjjzuy+QNzrH3+strunj0+rh6fu2lx1t9tv/ff+b+/Wm9vuOsSXz1cdUJOaW9TWNKmhSW2b1K5J7ZvU2KQOTeqmsbRNY2mbxtI1jaVrGkvXNJauaSxd01i62bH0TAc9Wj/8i6uJFMDEgxbA2SwGtDNqZMaDOhgIWR15Thwxhe4f0lC8Iw9qyaNaclJLzlrJvVFLDmrJrVpyp5bcqyVX66FerYd6tR6Koq+K5DM54Zhc8mwhk5a4/cMwJpc8W8rkkldcZXLJK64ieXjvFReZTO6gTA4hJnH/kLPYst+jg150KxkdIaOTeYU+VXsXkto7OoIEnBMHl7Q0qMnfkriPkoxL4j9KMi4JfpRkXJLwUZJxSeLFlMSbkNL04Icl2eVJC8mTLydPn6et9zzKM4pejDXmaXOeg23hIU/RK7c3zLO2zHOmnKfnkPaonuMkvDtveH9yeM69AWPiODyeN3w4MTwaxzm8n4SPp4fPWoNhHJ5ODh8zPRgYh+dTw4PNm0pw4/BkzhseTg5/bFpBGA8t2fOGd+cNP/uqjTbNhjh0nbnwDCk6D4KDn7v8QZ5kwMdRsvMX1ojJ4iHGgZrN3IsbQ2px9NdVM04SLyRJLCUZ3jNJzP0KpkqSjD6JuW9FHdUY59UpsjF2EHqfY1xAjrSAHPnyc2SzgBxhATnaBeToFpCjX0COuIAcT13ngMmbcDADlvksZ+8OnMqiSQvyaPFVg2GHHPUhkz5kVofcT+8KM9aYLef+k4P46h9M1cEdW1uOX93EMLPdsLm97gfNHpqjOO5Hod+Bv1S6YMXNWt9+WGRNsFgT/841yX3n4EKlJqGPkcSAbijeo6Ne9PmLYEzjSgb/20x825ccX06ixdcR2HdO9O0mIwTJ6Lm3Huygt57Qo2R0siV0EoxuDWd0oAk6q0Wff7OYDnTQiy754lhBd3rRvV501Isu2U0r6JLdtIKu102tXjd1kt0UAh3RuSxm71Oe7NlM8pRsvf/Oc48uel9SRpdsvRV0ydZbQY+SuyrF3aAjyejF3aBjwehlE/BGLzroRbd60Z1edK8XXXK3vIIe9KJLdtMKumQ3raDrdVPU66ao101Rr5uiXjdFvW6Ket0U9bopit6bvl2/CUVvZIvtA5RsvWX0INl6K+iSrbeC7rUezQNB9BlUZXTRh1CV0UWfQlVGF32wkMvv5iM/aVAG0ScLWVtAj5IPc6S84OnRqbJqcMd73V2c3McVJR9yVjz8CaLksx8r6JIPf6ygS7beCrpk662gqz3RD6LaI/0gqj3TD6LaQ/2AZFtvEV2vm5JeNyW9bkp63ZT0uinpdVPS66ak101Jr5uyUjd96Z/9Wj2sVzeb28MHC9393H4dfM7Q0+8ff3/Ti/8A","brillig_names":["create_company"],"assert_messages":{"99":"Storage slot 0 not allowed. Storage slots must start from 1.","154":"Array index out of bounds","186":"attempt to add with overflow","161":"attempt to add with overflow","174":"Array index out of bounds","66":"call to assert_max_bit_size","127":"Array index out of bounds","134":"attempt to add with overflow","83":"attempt to add with overflow"}}],"outputs":{"globals":{"storage":[{"fields":[{"name":"companies","value":{"fields":[{"name":"slot","value":{"kind":"integer","sign":false,"value":"0000000000000000000000000000000000000000000000000000000000000001"}}],"kind":"struct"}},{"name":"company_count","value":{"fields":[{"name":"slot","value":{"kind":"integer","sign":false,"value":"0000000000000000000000000000000000000000000000000000000000000002"}}],"kind":"struct"}}],"kind":"struct"}]},"structs":{"functions":[{"fields":[{"name":"parameters","type":{"fields":[{"name":"name","type":{"fields":[{"name":"value","type":{"kind":"field"}}],"kind":"struct","path":"compressed_string::field_compressed_string::FieldCompressedString"}},{"name":"email","type":{"fields":[{"name":"value","type":{"kind":"field"}}],"kind":"struct","path":"compressed_string::field_compressed_string::FieldCompressedString"}},{"name":"director","type":{"fields":[{"name":"value","type":{"kind":"field"}}],"kind":"struct","path":"compressed_string::field_compressed_string::FieldCompressedString"}},{"name":"total_shares","type":{"fields":[{"name":"lo","type":{"kind":"field"}},{"name":"hi","type":{"kind":"field"}}],"kind":"struct","path":"std::uint128::U128"}}],"kind":"struct","path":"CompanyRegistry::create_company_parameters"}}],"kind":"struct","path":"CompanyRegistry::create_company_abi"}]}},"file_map":{"144":{"path":"/Users/tiagofneto/nargo/github.com/AztecProtocol/aztec-packages/aztec-packages-v0.54.0/noir-projects/aztec-nr/aztec/src/state_vars/map.nr","source":"use dep::protocol_types::{storage::map::derive_storage_slot_in_map, traits::ToField};\nuse crate::state_vars::storage::Storage;\n\n// docs:start:map\nstruct Map<K, V, Context> {\n    context: Context,\n    storage_slot: Field,\n    state_var_constructor: fn(Context, Field) -> V,\n}\n// docs:end:map\n\nimpl<K, T, Context> Storage<T> for Map<K, T, Context> {}\n\nimpl<K, V, Context> Map<K, V, Context> {\n    // docs:start:new\n    pub fn new(\n        context: Context,\n        storage_slot: Field,\n        state_var_constructor: fn(Context, Field) -> V\n    ) -> Self {\n        assert(storage_slot != 0, \"Storage slot 0 not allowed. Storage slots must start from 1.\");\n        Map { context, storage_slot, state_var_constructor }\n    }\n    // docs:end:new\n\n    // docs:start:at\n    pub fn at(self, key: K) -> V where K: ToField {\n        // TODO(#1204): use a generator index for the storage slot\n        let derived_storage_slot = derive_storage_slot_in_map(self.storage_slot, key);\n\n        let state_var_constructor = self.state_var_constructor;\n        state_var_constructor(self.context, derived_storage_slot)\n    }\n    // docs:end:at\n}\n\n"},"152":{"path":"/Users/tiagofneto/nargo/github.com/AztecProtocol/aztec-packages/aztec-packages-v0.54.0/noir-projects/aztec-nr/aztec/src/state_vars/public_mutable.nr","source":"use crate::context::{PublicContext, UnconstrainedContext};\nuse crate::oracle::storage::storage_read;\nuse dep::protocol_types::traits::{Deserialize, Serialize};\nuse crate::state_vars::storage::Storage;\n\n// docs:start:public_mutable_struct\nstruct PublicMutable<T, Context> {\n    context: Context,\n    storage_slot: Field,\n}\n// docs:end:public_mutable_struct\n\nimpl<T, Context> Storage<T> for PublicMutable<T, Context> {}\n\nimpl<T, Context> PublicMutable<T, Context> {\n    // docs:start:public_mutable_struct_new\n    pub fn new(\n        // Note: Passing the contexts to new(...) just to have an interface compatible with a Map.\n        context: Context,\n        storage_slot: Field\n    ) -> Self {\n        assert(storage_slot != 0, \"Storage slot 0 not allowed. Storage slots must start from 1.\");\n        PublicMutable { context, storage_slot }\n    }\n    // docs:end:public_mutable_struct_new\n}\n\nimpl<T, T_SERIALIZED_LEN> PublicMutable<T, &mut PublicContext> where T: Serialize<T_SERIALIZED_LEN> + Deserialize<T_SERIALIZED_LEN> {\n    // docs:start:public_mutable_struct_read\n    pub fn read(self) -> T {\n        self.context.storage_read(self.storage_slot)\n    }\n    // docs:end:public_mutable_struct_read\n\n    // docs:start:public_mutable_struct_write\n    pub fn write(self, value: T) {\n        self.context.storage_write(self.storage_slot, value);\n    }\n    // docs:end:public_mutable_struct_write\n}\n\nimpl<T, T_SERIALIZED_LEN> PublicMutable<T, UnconstrainedContext> where T: Deserialize<T_SERIALIZED_LEN> {\n    unconstrained pub fn read(self) -> T {\n        self.context.storage_read(self.storage_slot)\n    }\n}\n"},"24":{"path":"std/field/mod.nr","source":"mod bn254;\nuse bn254::lt as bn254_lt;\n\nimpl Field {\n    /// Asserts that `self` can be represented in `bit_size` bits.\n    ///\n    /// # Failures\n    /// Causes a constraint failure for `Field` values exceeding `2^{bit_size}`.\n    // docs:start:assert_max_bit_size\n    pub fn assert_max_bit_size(self, bit_size: u32) {\n        // docs:end:assert_max_bit_size\n        crate::assert_constant(bit_size);\n        assert(bit_size < modulus_num_bits() as u32);\n        self.__assert_max_bit_size(bit_size);\n    }\n\n    #[builtin(apply_range_constraint)]\n    fn __assert_max_bit_size(self, bit_size: u32) {}\n\n    /// Decomposes `self` into its little endian bit decomposition as a `[u1; N]` array.\n    /// This slice will be zero padded should not all bits be necessary to represent `self`.\n    /// \n    /// # Failures\n    /// Causes a constraint failure for `Field` values exceeding `2^N` as the resulting slice will not\n    /// be able to represent the original `Field`.\n    ///\n    /// # Safety\n    /// Values of `N` equal to or greater than the number of bits necessary to represent the `Field` modulus\n    /// (e.g. 254 for the BN254 field) allow for multiple bit decompositions. This is due to how the `Field` will\n    /// wrap around due to overflow when verifying the decomposition.\n    #[builtin(to_le_bits)]\n    // docs:start:to_le_bits\n    pub fn to_le_bits<let N: u32>(self: Self) -> [u1; N] {}\n    // docs:end:to_le_bits\n\n    /// Decomposes `self` into its big endian bit decomposition as a `[u1; N]` array.\n    /// This array will be zero padded should not all bits be necessary to represent `self`.\n    /// \n    /// # Failures\n    /// Causes a constraint failure for `Field` values exceeding `2^N` as the resulting slice will not\n    /// be able to represent the original `Field`.\n    ///\n    /// # Safety\n    /// Values of `N` equal to or greater than the number of bits necessary to represent the `Field` modulus\n    /// (e.g. 254 for the BN254 field) allow for multiple bit decompositions. This is due to how the `Field` will\n    /// wrap around due to overflow when verifying the decomposition.\n    #[builtin(to_be_bits)]\n     // docs:start:to_be_bits\n    pub fn to_be_bits<let N: u32>(self: Self) -> [u1; N] {}\n    // docs:end:to_be_bits\n\n    /// Decomposes `self` into its little endian byte decomposition as a `[u8]` slice of length `byte_size`.\n    /// This slice will be zero padded should not all bytes be necessary to represent `self`.\n    /// \n    /// # Failures\n    /// Causes a constraint failure for `Field` values exceeding `2^{8*byte_size}` as the resulting slice will not\n    /// be able to represent the original `Field`.\n    ///\n    /// # Safety\n    /// Values of `byte_size` equal to or greater than the number of bytes necessary to represent the `Field` modulus\n    /// (e.g. 32 for the BN254 field) allow for multiple byte decompositions. This is due to how the `Field` will\n    /// wrap around due to overflow when verifying the decomposition.\n    // docs:start:to_le_bytes\n    pub fn to_le_bytes<let N: u32>(self: Self) -> [u8; N] {\n        self.to_le_radix(256)\n    }\n    // docs:end:to_le_bytes\n\n    /// Decomposes `self` into its big endian byte decomposition as a `[u8]` slice of length `byte_size`.\n    /// This slice will be zero padded should not all bytes be necessary to represent `self`.\n    /// \n    /// # Failures\n    /// Causes a constraint failure for `Field` values exceeding `2^{8*byte_size}` as the resulting slice will not\n    /// be able to represent the original `Field`.\n    ///\n    /// # Safety\n    /// Values of `byte_size` equal to or greater than the number of bytes necessary to represent the `Field` modulus\n    /// (e.g. 32 for the BN254 field) allow for multiple byte decompositions. This is due to how the `Field` will\n    /// wrap around due to overflow when verifying the decomposition.\n    // docs:start:to_be_bytes\n    pub fn to_be_bytes<let N: u32>(self: Self) -> [u8; N] {\n        self.to_be_radix(256)\n    }\n    // docs:end:to_be_bytes\n\n    // docs:start:to_le_radix\n    pub fn to_le_radix<let N: u32>(self: Self, radix: u32) -> [u8; N] {\n        crate::assert_constant(radix);\n        self.__to_le_radix(radix)\n    }\n    // docs:end:to_le_radix\n\n    // docs:start:to_be_radix\n    pub fn to_be_radix<let N: u32>(self: Self, radix: u32) -> [u8; N] {\n        crate::assert_constant(radix);\n        self.__to_be_radix(radix)\n    }\n    // docs:end:to_be_radix\n\n    // `_radix` must be less than 256\n    #[builtin(to_le_radix)]\n    fn __to_le_radix<let N: u32>(self, radix: u32) -> [u8; N] {}\n\n    #[builtin(to_be_radix)]\n    fn __to_be_radix<let N: u32>(self, radix: u32) -> [u8; N] {}\n\n    // Returns self to the power of the given exponent value.\n    // Caution: we assume the exponent fits into 32 bits\n    // using a bigger bit size impacts negatively the performance and should be done only if the exponent does not fit in 32 bits\n    pub fn pow_32(self, exponent: Field) -> Field {\n        let mut r: Field = 1;\n        let b: [u1; 32] = exponent.to_le_bits();\n\n        for i in 1..33 {\n            r *= r;\n            r = (b[32-i] as Field) * (r * self) + (1 - b[32-i] as Field) * r;\n        }\n        r\n    }\n\n    // Parity of (prime) Field element, i.e. sgn0(x mod p) = 0 if x âˆˆ {0, ..., p-1} is even, otherwise sgn0(x mod p) = 1.\n    pub fn sgn0(self) -> u1 {\n        self as u1\n    }\n\n    pub fn lt(self, another: Field) -> bool {\n        if crate::compat::is_bn254() {\n            bn254_lt(self, another)\n        } else {\n            lt_fallback(self, another)\n        }\n    }\n}\n\n#[builtin(modulus_num_bits)]\npub comptime fn modulus_num_bits() -> u64 {}\n\n#[builtin(modulus_be_bits)]\npub comptime fn modulus_be_bits() -> [u1] {}\n\n#[builtin(modulus_le_bits)]\npub comptime fn modulus_le_bits() -> [u1] {}\n\n#[builtin(modulus_be_bytes)]\npub comptime fn modulus_be_bytes() -> [u8] {}\n\n#[builtin(modulus_le_bytes)]\npub comptime fn modulus_le_bytes() -> [u8] {}\n\n// Convert a 32 byte array to a field element by modding\npub fn bytes32_to_field(bytes32: [u8; 32]) -> Field {\n    // Convert it to a field element\n    let mut v = 1;\n    let mut high = 0 as Field;\n    let mut low = 0 as Field;\n\n    for i in 0..16 {\n        high = high + (bytes32[15 - i] as Field) * v;\n        low = low + (bytes32[16 + 15 - i] as Field) * v;\n        v = v * 256;\n    }\n    // Abuse that a % p + b % p = (a + b) % p and that low < p\n    low + high * v\n}\n\nfn lt_fallback(x: Field, y: Field) -> bool {\n    let x_bytes: [u8; 32] = x.to_le_bytes();\n    let y_bytes: [u8; 32] = y.to_le_bytes();\n    let mut x_is_lt = false;\n    let mut done = false;\n    for i in 0..32 {\n        if (!done) {\n            let x_byte = x_bytes[32 - 1 - i] as u8;\n            let y_byte = y_bytes[32 - 1 - i] as u8;\n            let bytes_match = x_byte == y_byte;\n            if !bytes_match {\n                x_is_lt = x_byte < y_byte;\n                done = true;\n            }\n        }\n    }\n    x_is_lt\n}\n\nmod tests {\n    #[test]\n    // docs:start:to_be_bits_example\n    fn test_to_be_bits() {\n        let field = 2;\n        let bits: [u1; 8] = field.to_be_bits();\n        assert_eq(bits, [0, 0, 0, 0, 0, 0, 1, 0]);\n    }\n    // docs:end:to_be_bits_example\n\n    #[test]\n    // docs:start:to_le_bits_example\n    fn test_to_le_bits() {\n        let field = 2;\n        let bits: [u1; 8] = field.to_le_bits();\n        assert_eq(bits, [0, 1, 0, 0, 0, 0, 0, 0]);\n    }\n    // docs:end:to_le_bits_example\n\n    #[test]\n    // docs:start:to_be_bytes_example\n    fn test_to_be_bytes() {\n        let field = 2;\n        let bits: [u8; 8] = field.to_be_bytes();\n        assert_eq(bits, [0, 0, 0, 0, 0, 0, 0, 2]);\n    }\n    // docs:end:to_be_bytes_example\n\n    #[test]\n    // docs:start:to_le_bytes_example\n    fn test_to_le_bytes() {\n        let field = 2;\n        let bits: [u8; 8] = field.to_le_bytes();\n        assert_eq(bits, [2, 0, 0, 0, 0, 0, 0, 0]);\n    }\n    // docs:end:to_le_bytes_example\n\n    #[test]\n    // docs:start:to_be_radix_example\n    fn test_to_be_radix() {\n        let field = 2;\n        let bits: [u8; 8] = field.to_be_radix(256);\n        assert_eq(bits, [0, 0, 0, 0, 0, 0, 0, 2]);\n    }\n    // docs:end:to_be_radix_example\n\n    #[test]\n    // docs:start:to_le_radix_example\n    fn test_to_le_radix() {\n        let field = 2;\n        let bits: [u8; 8] = field.to_le_radix(256);\n        assert_eq(bits, [2, 0, 0, 0, 0, 0, 0, 0]);\n    }\n    // docs:end:to_le_radix_example\n}\n"},"257":{"path":"/Users/tiagofneto/nargo/github.com/AztecProtocol/aztec-packages/aztec-packages-v0.54.0/noir-projects/noir-protocol-circuits/crates/types/src/hash.nr","source":"use crate::{\n    abis::{\n    contract_class_function_leaf_preimage::ContractClassFunctionLeafPreimage,\n    function_selector::FunctionSelector, log_hash::{LogHash, ScopedLogHash, ScopedEncryptedLogHash},\n    note_hash::ScopedNoteHash, nullifier::ScopedNullifier\n},\n    address::{AztecAddress, EthAddress},\n    constants::{\n    FUNCTION_TREE_HEIGHT, GENERATOR_INDEX__SILOED_NOTE_HASH, GENERATOR_INDEX__OUTER_NULLIFIER,\n    GENERATOR_INDEX__VK, GENERATOR_INDEX__NOTE_HASH_NONCE, GENERATOR_INDEX__UNIQUE_NOTE_HASH,\n    MAX_ENCRYPTED_LOGS_PER_TX, MAX_NOTE_ENCRYPTED_LOGS_PER_TX\n},\n    merkle_tree::root::root_from_sibling_path,\n    messaging::l2_to_l1_message::{L2ToL1Message, ScopedL2ToL1Message},\n    recursion::verification_key::VerificationKey, traits::{is_empty, ToField},\n    utils::field::field_from_bytes_32_trunc\n};\n\npub fn sha256_to_field<let N: u32>(bytes_to_hash: [u8; N]) -> Field {\n    let sha256_hashed = std::hash::sha256(bytes_to_hash);\n    let hash_in_a_field = field_from_bytes_32_trunc(sha256_hashed);\n\n    hash_in_a_field\n}\n\npub fn private_functions_root_from_siblings(\n    selector: FunctionSelector,\n    vk_hash: Field,\n    function_leaf_index: Field,\n    function_leaf_sibling_path: [Field; FUNCTION_TREE_HEIGHT]\n) -> Field {\n    let function_leaf_preimage = ContractClassFunctionLeafPreimage { selector, vk_hash };\n    let function_leaf = function_leaf_preimage.hash();\n    root_from_sibling_path(function_leaf, function_leaf_index, function_leaf_sibling_path)\n}\n\nfn compute_note_hash_nonce(tx_hash: Field, note_index_in_tx: u32) -> Field {\n    // Hashing tx hash with note index in tx is guaranteed to be unique\n    poseidon2_hash_with_separator(\n        [\n        tx_hash,\n        note_index_in_tx as Field\n    ],\n        GENERATOR_INDEX__NOTE_HASH_NONCE\n    )\n}\n\npub fn compute_unique_note_hash(nonce: Field, note_hash: Field) -> Field {\n    let inputs = [nonce, note_hash];\n    poseidon2_hash_with_separator(inputs, GENERATOR_INDEX__UNIQUE_NOTE_HASH)\n}\n\npub fn compute_siloed_note_hash(app: AztecAddress, unique_note_hash: Field) -> Field {\n    poseidon2_hash_with_separator(\n        [\n        app.to_field(),\n        unique_note_hash\n    ],\n        GENERATOR_INDEX__SILOED_NOTE_HASH\n    )\n}\n\n/// Siloing in the context of Aztec refers to the process of hashing a note hash with a contract address (this way\n/// the note hash is scoped to a specific contract). This is used to prevent intermingling of notes between contracts.\npub fn silo_note_hash(note_hash: ScopedNoteHash, tx_hash: Field, note_index_in_tx: u32) -> Field {\n    if note_hash.contract_address.is_zero() {\n        0\n    } else {\n        let nonce = compute_note_hash_nonce(tx_hash, note_index_in_tx);\n        let unique_note_hash = compute_unique_note_hash(nonce, note_hash.value());\n        compute_siloed_note_hash(note_hash.contract_address, unique_note_hash)\n    }\n}\n\npub fn compute_siloed_nullifier(app: AztecAddress, nullifier: Field) -> Field {\n    poseidon2_hash_with_separator(\n        [\n        app.to_field(),\n        nullifier\n    ],\n        GENERATOR_INDEX__OUTER_NULLIFIER\n    )\n}\n\npub fn silo_nullifier(nullifier: ScopedNullifier) -> Field {\n    if nullifier.contract_address.is_zero() {\n        nullifier.value() // Return value instead of 0 because the first nullifier's contract address is zero.\n    } else {\n        compute_siloed_nullifier(nullifier.contract_address, nullifier.value())\n    }\n}\n\npub fn silo_encrypted_log_hash(log_hash: ScopedLogHash) -> Field {\n    // We assume contract address has already been masked\n    if log_hash.contract_address.is_zero() {\n        0\n    } else {\n        accumulate_sha256([log_hash.contract_address.to_field(), log_hash.log_hash.value])\n    }\n}\n\npub fn mask_encrypted_log_hash(scoped_log: ScopedEncryptedLogHash) -> AztecAddress {\n    if scoped_log.contract_address.is_zero() {\n        AztecAddress::from_field(0)\n    } else if (scoped_log.log_hash.randomness == 0) {\n        scoped_log.contract_address\n    } else {\n        AztecAddress::from_field(\n            poseidon2_hash_with_separator(\n                [scoped_log.contract_address.to_field(), scoped_log.log_hash.randomness],\n                0\n            )\n        )\n    }\n}\n\nfn compute_siloed_unencrypted_log_hash(address: AztecAddress, log_hash: Field) -> Field {\n    accumulate_sha256([address.to_field(), log_hash])\n}\n\npub fn silo_unencrypted_log_hash(log_hash: ScopedLogHash) -> Field {\n    if log_hash.contract_address.is_zero() {\n        0\n    } else {\n        compute_siloed_unencrypted_log_hash(log_hash.contract_address, log_hash.value())\n    }\n}\n\npub fn merkle_hash(left: Field, right: Field) -> Field {\n    poseidon2_hash([left, right])\n}\n\npub fn stdlib_recursion_verification_key_compress_native_vk(_vk: VerificationKey) -> Field {\n    // Original cpp code\n    // stdlib::recursion::verification_key<CT::bn254>::compress_native(private_call.vk, GeneratorIndex::VK);\n    // The above cpp method is only ever called on verification key, so it has been special cased here\n    let _hash_index = GENERATOR_INDEX__VK;\n    0\n}\n\npub fn compute_l2_to_l1_hash(\n    contract_address: AztecAddress,\n    recipient: EthAddress,\n    content: Field,\n    rollup_version_id: Field,\n    chain_id: Field\n) -> Field {\n    let mut bytes: BoundedVec<u8, 160> = BoundedVec::new();\n\n    let inputs = [contract_address.to_field(), rollup_version_id, recipient.to_field(), chain_id, content];\n    for i in 0..inputs.len() {\n        // TODO are bytes be in fr.to_buffer() ?\n        let item_bytes: [u8; 32] = inputs[i].to_be_bytes();\n        for j in 0..32 {\n            bytes.push(item_bytes[j]);\n        }\n    }\n\n    sha256_to_field(bytes.storage)\n}\n\npub fn silo_l2_to_l1_message(msg: ScopedL2ToL1Message, rollup_version_id: Field, chain_id: Field) -> Field {\n    if msg.contract_address.is_zero() {\n        0\n    } else {\n        compute_l2_to_l1_hash(\n            msg.contract_address,\n            msg.message.recipient,\n            msg.message.content,\n            rollup_version_id,\n            chain_id\n        )\n    }\n}\n\n// Computes sha256 hash of 2 input hashes.\n//\n// NB: This method now takes in two 31 byte fields - it assumes that any input\n// is the result of a sha_to_field hash and => is truncated\n//\n// TODO(Jan and David): This is used for the encrypted_log hashes.\n// Can we check to see if we can just use hash_to_field or pedersen_compress here?\n//\npub fn accumulate_sha256(input: [Field; 2]) -> Field {\n    // This is a note about the cpp code, since it takes an array of Fields\n    // instead of a U128.\n    // 4 Field elements when converted to bytes will usually\n    // occupy 4 * 32 = 128 bytes.\n    // However, this function is making the assumption that each Field\n    // only occupies 128 bits.\n    //\n    // TODO(David): This does not seem to be getting guaranteed anywhere in the code?\n\n    // Concatentate two fields into 32x2 = 64 bytes\n    // accumulate_sha256 assumes that the inputs are pre-truncated 31 byte numbers\n    let mut hash_input_flattened = [0; 64];\n    for offset in 0..input.len() {\n        let input_as_bytes: [u8; 32] = input[offset].to_be_bytes();\n        for byte_index in 0..32 {\n            hash_input_flattened[offset * 32 + byte_index] = input_as_bytes[byte_index];\n        }\n    }\n\n    sha256_to_field(hash_input_flattened)\n}\n\n// Computes the final logs hash for a tx.\n// NB: this assumes MAX_ENCRYPTED_LOGS_PER_TX == MAX_UNENCRYPTED_LOGS_PER_TX\n// to avoid doubling code, since we can't define the byte len to be 32*N directly.\npub fn compute_tx_logs_hash(logs: [LogHash; MAX_ENCRYPTED_LOGS_PER_TX]) -> Field {\n    // Convert each field element into a byte array and append the bytes to `hash_input_flattened`\n    let mut hash_input_flattened = [0; MAX_ENCRYPTED_LOGS_PER_TX * 32];\n    for offset in 0..MAX_ENCRYPTED_LOGS_PER_TX {\n        let input_as_bytes: [u8; 32] = logs[offset].value.to_be_bytes();\n        for byte_index in 0..32 {\n            hash_input_flattened[offset * 32 + byte_index] = input_as_bytes[byte_index];\n        }\n    }\n    // Ideally we would push to a slice then hash, but there is no sha_slice\n    // Hardcode to 256 bytes for now\n    let mut hash = sha256_to_field(hash_input_flattened);\n    // Not having a 0 value hash for empty logs causes issues with empty txs\n    // used for padding. Returning early is currently unsupported.\n    // We always provide sorted logs here, so 0 being empty means all are empty.\n    if is_empty(logs[0]) {\n        hash = 0;\n    }\n    hash\n}\n\npub fn compute_tx_note_logs_hash(logs: [LogHash; MAX_NOTE_ENCRYPTED_LOGS_PER_TX]) -> Field {\n    // Convert each field element into a byte array and append the bytes to `hash_input_flattened`\n    let mut hash_input_flattened = [0; MAX_NOTE_ENCRYPTED_LOGS_PER_TX * 32];\n    for offset in 0..MAX_NOTE_ENCRYPTED_LOGS_PER_TX {\n        let input_as_bytes: [u8; 32] = logs[offset].value.to_be_bytes();\n        for byte_index in 0..32 {\n            hash_input_flattened[offset * 32 + byte_index] = input_as_bytes[byte_index];\n        }\n    }\n    // Ideally we would push to a slice then hash, but there is no sha_slice\n    // Hardcode to 256 bytes for now\n    let mut hash = sha256_to_field(hash_input_flattened);\n    // Not having a 0 value hash for empty logs causes issues with empty txs\n    // used for padding. Returning early is currently unsupported.\n    // We always provide sorted logs here, so 0 being empty means all are empty.\n    if is_empty(logs[0]) {\n        hash = 0;\n    }\n    hash\n}\n\npub fn pedersen_hash<let N: u32>(inputs: [Field; N], hash_index: u32) -> Field {\n    std::hash::pedersen_hash_with_separator(inputs, hash_index)\n}\n\npub fn poseidon2_hash<let N: u32>(inputs: [Field; N]) -> Field {\n    std::hash::poseidon2::Poseidon2::hash(inputs, N)\n}\n\n#[no_predicates]\npub fn poseidon2_hash_with_separator<let N: u32, T>(\n    inputs: [Field; N],\n    separator: T\n) -> Field where T: ToField {\n    // We manually hash the inputs here, since we cannot express with the type system a constant size inputs array of N + 1\n    let in_len = N + 1;\n    let two_pow_64 = 18446744073709551616;\n    let iv : Field = (in_len as Field) * two_pow_64;\n    let mut sponge = std::hash::poseidon2::Poseidon2::new(iv);\n    sponge.absorb(separator.to_field());\n\n    for i in 0..inputs.len() {\n        sponge.absorb(inputs[i]);\n    }\n\n    sponge.squeeze()\n}\n\n#[test]\nfn smoke_sha256_to_field() {\n    let full_buffer = [\n        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n        20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39,\n        40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59,\n        60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79,\n        80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99,\n        100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n        120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159\n    ];\n    let result = sha256_to_field(full_buffer);\n\n    assert(result == 0x448ebbc9e1a31220a2f3830c18eef61b9bd070e5084b7fa2a359fe729184c7);\n\n    // to show correctness of the current ver (truncate one byte) vs old ver (mod full bytes):\n    let result_bytes = std::hash::sha256(full_buffer);\n    let truncated_field = crate::utils::field::field_from_bytes_32_trunc(result_bytes);\n    assert(truncated_field == result);\n    let mod_res = result + (result_bytes[31] as Field);\n    assert(mod_res == 0x448ebbc9e1a31220a2f3830c18eef61b9bd070e5084b7fa2a359fe729184e0);\n}\n\n#[test]\nfn compute_l2_l1_hash() {\n    // All zeroes\n    let hash_result = compute_l2_to_l1_hash(AztecAddress::from_field(0), EthAddress::zero(), 0, 0, 0);\n    assert(hash_result == 0xb393978842a0fa3d3e1470196f098f473f9678e72463cb65ec4ab5581856c2);\n\n    // Non-zero case\n    let hash_result = compute_l2_to_l1_hash(AztecAddress::from_field(1), EthAddress::from_field(3), 5, 2, 4);\n    assert(hash_result == 0x3f88c1044a05e5340ed20466276500f6d45ca5603913b9091e957161734e16);\n}\n\n#[test]\nfn silo_l2_to_l1_message_matches_typescript() {\n    let version = 4;\n    let chainId = 5;\n\n    let hash = silo_l2_to_l1_message(\n        ScopedL2ToL1Message {\n        message: L2ToL1Message { recipient: EthAddress::from_field(1), content: 2, counter: 0 },\n        contract_address: AztecAddress::from_field(3)\n    },\n        version,\n        chainId\n    );\n\n    // The following value was generated by `l2_to_l1_message.test.ts`\n    let hash_from_typescript = 0x00c6155d69febb9d5039b374dd4f77bf57b7c881709aa524a18acaa0bd57476a;\n\n    assert_eq(hash, hash_from_typescript);\n}\n"},"27":{"path":"std/hash/mod.nr","source":"mod poseidon;\nmod mimc;\nmod poseidon2;\nmod keccak;\nmod sha256;\nmod sha512;\n\nuse crate::default::Default;\nuse crate::uint128::U128;\nuse crate::collections::vec::Vec;\nuse crate::embedded_curve_ops::{EmbeddedCurvePoint, EmbeddedCurveScalar, multi_scalar_mul, multi_scalar_mul_slice};\nuse crate::meta::derive_via;\n\n// Kept for backwards compatibility\npub use sha256::{digest, sha256, sha256_compression, sha256_var};\n\n#[foreign(blake2s)]\n// docs:start:blake2s\npub fn blake2s<let N: u32>(input: [u8; N]) -> [u8; 32]\n// docs:end:blake2s\n{}\n\n#[foreign(blake3)]\n// docs:start:blake3\npub fn blake3<let N: u32>(input: [u8; N]) -> [u8; 32]\n// docs:end:blake3\n{}\n\n// docs:start:pedersen_commitment\npub fn pedersen_commitment<let N: u32>(input: [Field; N]) -> EmbeddedCurvePoint {\n    // docs:end:pedersen_commitment\n    pedersen_commitment_with_separator(input, 0)\n}\n\npub fn pedersen_hash_with_separator<let N: u32>(input: [Field; N], separator: u32) -> Field {\n    __pedersen_hash_with_separator(input, separator)\n}\n\nfn pedersen_commitment_with_separator<let N: u32>(input: [Field; N], separator: u32) -> EmbeddedCurvePoint {\n    let value = __pedersen_commitment_with_separator(input, separator);\n    if (value[0] == 0) & (value[1] == 0) {\n        EmbeddedCurvePoint { x: 0, y: 0, is_infinite: true }\n    } else {\n        EmbeddedCurvePoint { x: value[0], y: value[1], is_infinite: false }\n    }\n}\n\n#[no_predicates]\nfn pedersen_commitment_with_separator_noir<let N: u32>(input: [Field; N], separator: u32) -> EmbeddedCurvePoint {\n    let mut points = [EmbeddedCurveScalar { lo: 0, hi: 0 }; N];\n    for i in 0..N {\n        // we use the unsafe version because the multi_scalar_mul will constrain the scalars.\n        points[i] = from_field_unsafe(input[i]);\n    }\n    let generators = derive_generators(\"DEFAULT_DOMAIN_SEPARATOR\".as_bytes(), separator);\n    multi_scalar_mul(generators, points)\n}\n\n#[no_predicates]\nfn pedersen_hash_with_separator_noir<let N: u32>(input: [Field; N], separator: u32) -> Field {\n    let mut scalars: Vec<EmbeddedCurveScalar> = Vec::from_slice([EmbeddedCurveScalar { lo: 0, hi: 0 }; N].as_slice()); //Vec::new();\n\n    for i in 0..N {\n        scalars.set(i, from_field_unsafe(input[i]));\n    }\n    scalars.push(EmbeddedCurveScalar { lo: N as Field, hi: 0 as Field });\n    let domain_generators :[EmbeddedCurvePoint; N]= derive_generators(\"DEFAULT_DOMAIN_SEPARATOR\".as_bytes(), separator);\n    let mut vec_generators = Vec::new();\n    for i in 0..N {\n        vec_generators.push(domain_generators[i]);\n    }\n    let length_generator : [EmbeddedCurvePoint; 1] = derive_generators(\"pedersen_hash_length\".as_bytes(), 0);\n    vec_generators.push(length_generator[0]);\n    multi_scalar_mul_slice(vec_generators.slice, scalars.slice)[0]\n}\n\n// docs:start:pedersen_hash\npub fn pedersen_hash<let N: u32>(input: [Field; N]) -> Field\n// docs:end:pedersen_hash\n{\n    __pedersen_hash_with_separator(input, 0)\n}\n\n#[foreign(pedersen_hash)]\nfn __pedersen_hash_with_separator<let N: u32>(input: [Field; N], separator: u32) -> Field {}\n\n#[foreign(pedersen_commitment)]\nfn __pedersen_commitment_with_separator<let N: u32>(input: [Field; N], separator: u32) -> [Field; 2] {}\n\n#[field(bn254)]\nfn derive_generators<let N: u32, let M: u32>(domain_separator_bytes: [u8; M], starting_index: u32) -> [EmbeddedCurvePoint; N] {\n    crate::assert_constant(domain_separator_bytes);\n    // TODO(https://github.com/noir-lang/noir/issues/5672): Add back assert_constant on starting_index\n    __derive_generators(domain_separator_bytes, starting_index)\n}\n\n#[builtin(derive_pedersen_generators)]\n#[field(bn254)]\nfn __derive_generators<let N: u32, let M: u32>(\n    domain_separator_bytes: [u8; M],\n    starting_index: u32\n) -> [EmbeddedCurvePoint; N] {}\n\n#[field(bn254)]\n    // Same as from_field but:\n    // does not assert the limbs are 128 bits\n    // does not assert the decomposition does not overflow the EmbeddedCurveScalar\n    fn from_field_unsafe(scalar: Field) -> EmbeddedCurveScalar {\n    let (xlo, xhi) = unsafe {\n        crate::field::bn254::decompose_hint(scalar)\n    };\n    // Check that the decomposition is correct\n    assert_eq(scalar, xlo + crate::field::bn254::TWO_POW_128 * xhi);\n    EmbeddedCurveScalar { lo: xlo, hi: xhi }\n}\n\npub fn hash_to_field(inputs: [Field]) -> Field {\n    let mut sum = 0;\n\n    for input in inputs {\n        let input_bytes: [u8; 32] = input.to_le_bytes();\n        sum += crate::field::bytes32_to_field(blake2s(input_bytes));\n    }\n\n    sum\n}\n\n// docs:start:keccak256\npub fn keccak256<let N: u32>(input: [u8; N], message_size: u32) -> [u8; 32]\n// docs:end:keccak256\n{\n    crate::hash::keccak::keccak256(input, message_size)\n}\n\n#[foreign(poseidon2_permutation)]\npub fn poseidon2_permutation<let N: u32>(_input: [Field; N], _state_length: u32) -> [Field; N] {}\n\n// Generic hashing support. \n// Partially ported and impacted by rust.\n\n// Hash trait shall be implemented per type.\n#[derive_via(derive_hash)]\ntrait Hash {\n    fn hash<H>(self, state: &mut H) where H: Hasher;\n}\n\n// docs:start:derive_hash\ncomptime fn derive_hash(s: StructDefinition) -> Quoted {\n    let name = quote { Hash };\n    let signature = quote { fn hash<H>(_self: Self, _state: &mut H) where H: std::hash::Hasher };\n    let for_each_field = |name| quote { _self.$name.hash(_state); };\n    crate::meta::make_trait_impl(s, name, signature, for_each_field, quote {}, |fields| fields)\n}\n// docs:end:derive_hash\n\n// Hasher trait shall be implemented by algorithms to provide hash-agnostic means.\n// TODO: consider making the types generic here ([u8], [Field], etc.)\ntrait Hasher{\n    fn finish(self) -> Field;\n    \n    fn write(&mut self, input: Field);\n}\n\n// BuildHasher is a factory trait, responsible for production of specific Hasher.\ntrait BuildHasher<H> where H: Hasher{\n    fn build_hasher(self) -> H;\n}\n\nstruct BuildHasherDefault<H>;\n\nimpl<H> BuildHasher<H> for BuildHasherDefault<H>\nwhere \n    H: Hasher + Default\n{\n    fn build_hasher(_self: Self) -> H{\n        H::default()\n    }\n}\n\nimpl<H> Default for BuildHasherDefault<H>\nwhere \n    H: Hasher + Default\n{\n    fn default() -> Self{\n        BuildHasherDefault{}\n    }    \n}\n\nimpl Hash for Field {\n    fn hash<H>(self, state: &mut H) where H: Hasher{\n        H::write(state, self);\n    }\n}\n\nimpl Hash for u1 {\n    fn hash<H>(self, state: &mut H) where H: Hasher{\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u8 {\n    fn hash<H>(self, state: &mut H) where H: Hasher{\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u16 {\n    fn hash<H>(self, state: &mut H) where H: Hasher{\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u32 {\n    fn hash<H>(self, state: &mut H) where H: Hasher{\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u64 {\n    fn hash<H>(self, state: &mut H) where H: Hasher{\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for i8 {\n    fn hash<H>(self, state: &mut H) where H: Hasher{\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for i16 {\n    fn hash<H>(self, state: &mut H) where H: Hasher{\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for i32 {\n    fn hash<H>(self, state: &mut H) where H: Hasher{\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for i64 {\n    fn hash<H>(self, state: &mut H) where H: Hasher{\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for bool {\n    fn hash<H>(self, state: &mut H) where H: Hasher{\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for () {\n    fn hash<H>(_self: Self, _state: &mut H) where H: Hasher {}\n}\n\nimpl Hash for U128 {\n    fn hash<H>(self, state: &mut H) where H: Hasher{\n        H::write(state, self.lo as Field);\n        H::write(state, self.hi as Field);\n    }\n}\n\nimpl<T, let N: u32> Hash for [T; N] where T: Hash {\n    fn hash<H>(self, state: &mut H) where H: Hasher{\n        for elem in self {\n            elem.hash(state);\n        }\n    }\n}\n\nimpl<T> Hash for [T] where T: Hash {\n    fn hash<H>(self, state: &mut H) where H: Hasher{\n        self.len().hash(state);\n        for elem in self {\n            elem.hash(state);\n        }\n    }\n}\n\nimpl<A, B> Hash for (A, B) where A: Hash, B: Hash {\n    fn hash<H>(self, state: &mut H) where H: Hasher{\n        self.0.hash(state);\n        self.1.hash(state);\n    }\n}\n\nimpl<A, B, C> Hash for (A, B, C) where A: Hash, B: Hash, C: Hash {\n    fn hash<H>(self, state: &mut H) where H: Hasher{\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n    }\n}\n\nimpl<A, B, C, D> Hash for (A, B, C, D) where A: Hash, B: Hash, C: Hash, D: Hash {\n    fn hash<H>(self, state: &mut H) where H: Hasher{\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n        self.3.hash(state);\n    }\n}\n\nimpl<A, B, C, D, E> Hash for (A, B, C, D, E) where A: Hash, B: Hash, C: Hash, D: Hash, E: Hash {\n    fn hash<H>(self, state: &mut H) where H: Hasher{\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n        self.3.hash(state);\n        self.4.hash(state);\n    }\n}\n\n// Some test vectors for Pedersen hash and Pedersen Commitment.\n// They have been generated using the same functions so the tests are for now useless\n// but they will be useful when we switch to Noir implementation.\n#[test]\nfn assert_pedersen() {\n    assert_eq(\n        pedersen_hash_with_separator([1], 1), 0x1b3f4b1a83092a13d8d1a59f7acb62aba15e7002f4440f2275edb99ebbc2305f\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1], 1), EmbeddedCurvePoint {\n        x: 0x054aa86a73cb8a34525e5bbed6e43ba1198e860f5f3950268f71df4591bde402,\n        y: 0x209dcfbf2cfb57f9f6046f44d71ac6faf87254afc7407c04eb621a6287cac126,\n        is_infinite: false\n    }\n    );\n\n    assert_eq(\n        pedersen_hash_with_separator([1, 2], 2), 0x26691c129448e9ace0c66d11f0a16d9014a9e8498ee78f4d69f0083168188255\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2], 2), EmbeddedCurvePoint {\n        x: 0x2e2b3b191e49541fe468ec6877721d445dcaffe41728df0a0eafeb15e87b0753,\n        y: 0x2ff4482400ad3a6228be17a2af33e2bcdf41be04795f9782bd96efe7e24f8778,\n        is_infinite: false\n    }\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3], 3), 0x0bc694b7a1f8d10d2d8987d07433f26bd616a2d351bc79a3c540d85b6206dbe4\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3], 3), EmbeddedCurvePoint {\n        x: 0x1fee4e8cf8d2f527caa2684236b07c4b1bad7342c01b0f75e9a877a71827dc85,\n        y: 0x2f9fedb9a090697ab69bf04c8bc15f7385b3e4b68c849c1536e5ae15ff138fd1,\n        is_infinite: false\n    }\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4], 4), 0xdae10fb32a8408521803905981a2b300d6a35e40e798743e9322b223a5eddc\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4], 4), EmbeddedCurvePoint {\n        x: 0x07ae3e202811e1fca39c2d81eabe6f79183978e6f12be0d3b8eda095b79bdbc9,\n        y: 0x0afc6f892593db6fbba60f2da558517e279e0ae04f95758587760ba193145014,\n        is_infinite: false\n    }\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5], 5), 0xfc375b062c4f4f0150f7100dfb8d9b72a6d28582dd9512390b0497cdad9c22\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5], 5), EmbeddedCurvePoint {\n        x: 0x1754b12bd475a6984a1094b5109eeca9838f4f81ac89c5f0a41dbce53189bb29,\n        y: 0x2da030e3cfcdc7ddad80eaf2599df6692cae0717d4e9f7bfbee8d073d5d278f7,\n        is_infinite: false\n    }\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6], 6), 0x1696ed13dc2730062a98ac9d8f9de0661bb98829c7582f699d0273b18c86a572\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6], 6), EmbeddedCurvePoint {\n        x: 0x190f6c0e97ad83e1e28da22a98aae156da083c5a4100e929b77e750d3106a697,\n        y: 0x1f4b60f34ef91221a0b49756fa0705da93311a61af73d37a0c458877706616fb,\n        is_infinite: false\n    }\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7], 7), 0x128c0ff144fc66b6cb60eeac8a38e23da52992fc427b92397a7dffd71c45ede3\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7], 7), EmbeddedCurvePoint {\n        x: 0x015441e9d29491b06563fac16fc76abf7a9534c715421d0de85d20dbe2965939,\n        y: 0x1d2575b0276f4e9087e6e07c2cb75aa1baafad127af4be5918ef8a2ef2fea8fc,\n        is_infinite: false\n    }\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8], 8), 0x2f960e117482044dfc99d12fece2ef6862fba9242be4846c7c9a3e854325a55c\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8], 8), EmbeddedCurvePoint {\n        x: 0x1657737676968887fceb6dd516382ea13b3a2c557f509811cd86d5d1199bc443,\n        y: 0x1f39f0cb569040105fa1e2f156521e8b8e08261e635a2b210bdc94e8d6d65f77,\n        is_infinite: false\n    }\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9], 9), 0x0c96db0790602dcb166cc4699e2d306c479a76926b81c2cb2aaa92d249ec7be7\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9], 9), EmbeddedCurvePoint {\n        x: 0x0a3ceae42d14914a432aa60ec7fded4af7dad7dd4acdbf2908452675ec67e06d,\n        y: 0xfc19761eaaf621ad4aec9a8b2e84a4eceffdba78f60f8b9391b0bd9345a2f2,\n        is_infinite: false\n    }\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 10), 0x2cd37505871bc460a62ea1e63c7fe51149df5d0801302cf1cbc48beb8dff7e94\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 10), EmbeddedCurvePoint {\n        x: 0x2fb3f8b3d41ddde007c8c3c62550f9a9380ee546fcc639ffbb3fd30c8d8de30c,\n        y: 0x300783be23c446b11a4c0fabf6c91af148937cea15fcf5fb054abf7f752ee245,\n        is_infinite: false\n    }\n    );\n}\n\n"},"279":{"path":"/Users/tiagofneto/nargo/github.com/AztecProtocol/aztec-packages/aztec-packages-v0.54.0/noir-projects/noir-protocol-circuits/crates/types/src/storage/map.nr","source":"use crate::{hash::pedersen_hash, traits::ToField};\n\npub fn derive_storage_slot_in_map<K>(storage_slot: Field, key: K) -> Field where K: ToField {\n    pedersen_hash([storage_slot, key.to_field()], 0)\n}\n\nmod test {\n    use crate::{address::AztecAddress, storage::map::derive_storage_slot_in_map};\n\n    #[test]\n    fn test_derive_storage_slot_in_map_matches_typescript() {\n        let map_slot = 0x132258fb6962c4387ba659d9556521102d227549a386d39f0b22d1890d59c2b5;\n        let key = AztecAddress::from_field(0x302dbc2f9b50a73283d5fb2f35bc01eae8935615817a0b4219a057b2ba8a5a3f);\n\n        let slot = derive_storage_slot_in_map(map_slot, key);\n\n        // The following value was generated by `map_slot.test.ts`\n        let slot_from_typescript = 0x2499880e2b1b831785c17286f99a0d5122fee784ce7b1c04e380c4a991da819a;\n\n        assert_eq(slot, slot_from_typescript);\n    }\n}\n"},"290":{"path":"/Users/tiagofneto/nargo/github.com/AztecProtocol/aztec-packages/aztec-packages-v0.54.0/noir-projects/noir-protocol-circuits/crates/types/src/traits.nr","source":"use crate::utils::field::field_from_bytes;\n\n// Trait: is_empty\n//\n// The general is_empty trait checks if a data type is is empty,\n// and it defines empty for the basic data types as 0.\n//\n// If a Field is equal to zero, then it is regarded as zero.\n// We will go with this definition for now, however it can be problematic \n// if a value can actually be zero. In a future refactor, we can \n// use the optional type for safety. Doing it now would lead to a worse devex\n// and would make it harder to sync up with the cpp code.\n// Preferred over Default trait to convey intent, as default doesn't necessarily mean empty.\ntrait Empty {\n    fn empty() -> Self;\n}\n\nimpl Empty for Field { fn empty() -> Self {0} }\n\nimpl Empty for u1 { fn empty() -> Self {0} }\nimpl Empty for u8 { fn empty() -> Self {0} }\nimpl Empty for u32 { fn empty() -> Self {0} }\nimpl Empty for u64 { fn empty() -> Self {0} }\nimpl Empty for U128 { fn empty() -> Self {U128::from_integer(0)} }\n\npub fn is_empty<T>(item: T) -> bool where T: Empty + Eq {\n    item.eq(T::empty())\n}\n\npub fn is_empty_array<T, let N: u32>(array: [T; N]) -> bool where T: Empty + Eq {\n    array.all(|elem| is_empty(elem))\n}\n\ntrait Hash {\n    fn hash(self) -> Field;\n}\n\ntrait ToField {\n    fn to_field(self) -> Field;\n}\n\nimpl ToField for Field {\n    fn to_field(self) -> Field {\n        self\n    }\n}\n\nimpl ToField for bool { fn to_field(self) -> Field { self as Field } }\nimpl ToField for u1 { fn to_field(self) -> Field { self as Field } }\nimpl ToField for u8 { fn to_field(self) -> Field { self as Field } }\nimpl ToField for u32 { fn to_field(self) -> Field { self as Field } }\nimpl ToField for u64 { fn to_field(self) -> Field { self as Field } }\nimpl ToField for U128 {\n    fn to_field(self) -> Field {\n        self.to_integer()\n    }\n}\nimpl<let N: u32> ToField for str<N> {\n    fn to_field(self) -> Field {\n        assert(N < 32, \"String doesn't fit in a field, consider using Serialize instead\");\n        field_from_bytes(self.as_bytes(), true)\n    }\n}\n\ntrait FromField {\n    fn from_field(value: Field) -> Self;\n}\n\nimpl FromField for Field {\n    fn from_field(value: Field) -> Self {\n        value\n    }\n}\n\nimpl FromField for bool { fn from_field(value: Field) -> Self { value as bool } }\nimpl FromField for u1 { fn from_field(value: Field) -> Self { value as u1 } }\nimpl FromField for u8 { fn from_field(value: Field) -> Self { value as u8 } }\nimpl FromField for u32 { fn from_field(value: Field) -> Self { value as u32 } }\nimpl FromField for u64 { fn from_field(value: Field) -> Self { value as u64 } }\nimpl FromField for U128 {\n    fn from_field(value: Field) -> Self {\n        U128::from_integer(value)\n    }\n}\n\n// docs:start:serialize\ntrait Serialize<let N: u32> {\n    fn serialize(self) -> [Field; N];\n}\n// docs:end:serialize\n\nimpl<let N: u32> Serialize<N> for [Field; N] {\n    fn serialize(self) -> [Field; N] {\n        self\n    }\n}\nimpl<let N: u32> Serialize<N> for str<N> {\n    fn serialize(self) -> [Field; N] {\n        let mut result = [0; N];\n        let bytes: [u8; N] = self.as_bytes();\n        for i in 0..N {\n            result[i] = field_from_bytes([bytes[i];1], true);\n        }\n        result\n    }\n}\n\n// docs:start:deserialize\ntrait Deserialize<let N: u32> {\n    fn deserialize(fields: [Field; N]) -> Self;\n}\n// docs:end:deserialize\n\nimpl<let N: u32> Deserialize<N> for [Field; N] {\n    fn deserialize(fields: [Field; N]) -> Self {\n        fields\n    }\n}\n"},"294":{"path":"/Users/tiagofneto/nargo/github.com/AztecProtocol/aztec-packages/aztec-packages-v0.54.0/noir-projects/noir-protocol-circuits/crates/types/src/type_serialization.nr","source":"use crate::traits::{Serialize, Deserialize};\n\nglobal BOOL_SERIALIZED_LEN: Field = 1;\nglobal U8_SERIALIZED_LEN: Field = 1;\nglobal U32_SERIALIZED_LEN: Field = 1;\nglobal U64_SERIALIZED_LEN: Field = 1;\nglobal U128_SERIALIZED_LEN: Field = 1;\nglobal FIELD_SERIALIZED_LEN: Field = 1;\n\nimpl Serialize<BOOL_SERIALIZED_LEN> for bool {\n    fn serialize(self) -> [Field; BOOL_SERIALIZED_LEN] {\n        [self as Field]\n    }\n}\n\nimpl Deserialize<BOOL_SERIALIZED_LEN> for bool {\n    fn deserialize(fields: [Field; BOOL_SERIALIZED_LEN]) -> bool {\n        fields[0] as bool\n    }\n}\n\nimpl Serialize<U8_SERIALIZED_LEN> for u8 {\n    fn serialize(self) -> [Field; U32_SERIALIZED_LEN] {\n        [self as Field]\n    }\n}\n\nimpl Deserialize<U8_SERIALIZED_LEN> for u8 {\n    fn deserialize(fields: [Field; U8_SERIALIZED_LEN]) -> Self {\n        fields[0] as u8\n    }\n}\n\nimpl Serialize<U32_SERIALIZED_LEN> for u32 {\n    fn serialize(self) -> [Field; U32_SERIALIZED_LEN] {\n        [self as Field]\n    }\n}\n\nimpl Deserialize<U32_SERIALIZED_LEN> for u32 {\n    fn deserialize(fields: [Field; U32_SERIALIZED_LEN]) -> Self {\n        fields[0] as u32\n    }\n}\n\nimpl Serialize<U64_SERIALIZED_LEN> for u64 {\n    fn serialize(self) -> [Field; U64_SERIALIZED_LEN] {\n        [self as Field]\n    }\n}\n\nimpl Deserialize<U64_SERIALIZED_LEN> for u64 {\n    fn deserialize(fields: [Field; U64_SERIALIZED_LEN]) -> Self {\n        fields[0] as u64\n    }\n}\n\nimpl Serialize<U128_SERIALIZED_LEN> for U128 {\n    fn serialize(self) -> [Field; 1] {\n        [self.to_integer()]\n    }\n\n}\n\nimpl Deserialize<U128_SERIALIZED_LEN> for U128 {\n    fn deserialize(fields: [Field; U128_SERIALIZED_LEN]) -> Self {\n        U128::from_integer(fields[0])\n    }\n}\n\nimpl Serialize<FIELD_SERIALIZED_LEN> for Field {\n    fn serialize(self) -> [Field; U32_SERIALIZED_LEN] {\n        [self]\n    }\n}\n\nimpl Deserialize<FIELD_SERIALIZED_LEN> for Field {\n    fn deserialize(fields: [Field; FIELD_SERIALIZED_LEN]) -> Self {\n        fields[0]\n    }\n}\n"},"65":{"path":"std/uint128.nr","source":"use crate::ops::{Add, Sub, Mul, Div, Rem, Not, BitOr, BitAnd, BitXor, Shl, Shr};\nuse crate::cmp::{Eq, Ord, Ordering};\n\nglobal pow64 : Field = 18446744073709551616; //2^64;\nglobal pow63 : Field = 9223372036854775808; // 2^63;\nstruct U128 {\n    lo: Field,\n    hi: Field,\n}\n\nimpl U128 {\n\n    pub fn from_u64s_le(lo: u64, hi: u64) -> U128 {\n        // in order to handle multiplication, we need to represent the product of two u64 without overflow\n        assert(crate::field::modulus_num_bits() as u32 > 128);\n        U128 { lo: lo as Field, hi: hi as Field }\n    }\n\n    pub fn from_u64s_be(hi: u64, lo: u64) -> U128 {\n        U128::from_u64s_le(lo, hi)\n    }\n\n    pub fn zero() -> U128 {\n        U128 { lo: 0, hi: 0 }\n    }\n\n    pub fn one() -> U128 {\n        U128 { lo: 1, hi: 0 }\n    }\n    pub fn from_le_bytes(bytes: [u8; 16]) -> U128 {\n        let mut lo = 0;\n        let mut base = 1;\n        for i in 0..8 {\n            lo += (bytes[i] as Field)*base;\n            base *= 256;\n        }\n        let mut hi = 0;\n        base = 1;\n        for i in 8..16 {\n            hi += (bytes[i] as Field)*base;\n            base *= 256;\n        }\n        U128 { lo, hi }\n    }\n\n    pub fn to_be_bytes(self: Self) -> [u8; 16] {\n        let lo: [u8; 8] = self.lo.to_be_bytes();\n        let hi: [u8; 8] = self.hi.to_be_bytes();\n        let mut bytes = [0; 16];\n        for i in 0..8 {\n            bytes[i] = hi[i];\n            bytes[i+8] = lo[i];\n        }\n        bytes\n    }\n\n    pub fn to_le_bytes(self: Self) -> [u8; 16] {\n        let lo: [u8; 8] = self.lo.to_le_bytes();\n        let hi: [u8; 8] = self.hi.to_le_bytes();\n        let mut bytes = [0; 16];\n        for i in 0..8 {\n            bytes[i] = lo[i];\n            bytes[i+8] = hi[i];\n        }\n        bytes\n    }\n\n    pub fn from_hex<let N: u32>(hex: str<N>) -> U128 {\n        let N = N as u32;\n        let bytes = hex.as_bytes();\n        // string must starts with \"0x\"\n        assert((bytes[0] == 48) & (bytes[1] == 120), \"Invalid hexadecimal string\");\n        assert(N < 35, \"Input does not fit into a U128\");\n\n        let mut lo = 0;\n        let mut hi = 0;\n        let mut base = 1;\n        if N <= 18 {\n            for i in 0..N - 2 {\n                lo += U128::decode_ascii(bytes[N-i-1])*base;\n                base = base*16;\n            }\n        } else {\n            for i in 0..16 {\n                lo += U128::decode_ascii(bytes[N-i-1])*base;\n                base = base*16;\n            }\n            base = 1;\n            for i in 17..N - 1 {\n                hi += U128::decode_ascii(bytes[N-i])*base;\n                base = base*16;\n            }\n        }\n        U128 { lo: lo as Field, hi: hi as Field }\n    }\n\n    unconstrained fn uconstrained_check_is_upper_ascii(ascii: u8) -> bool {\n        ((ascii >= 65) & (ascii <= 90)) // Between 'A' and 'Z'\n    }\n\n    fn decode_ascii(ascii: u8) -> Field {\n        (if ascii < 58 {\n            ascii - 48\n        } else {\n            let ascii = ascii + 32 * (unsafe {\n                        U128::uconstrained_check_is_upper_ascii(ascii) as u8\n                    });\n            assert(ascii >= 97); // enforce >= 'a'\n            assert(ascii <= 102); // enforce <= 'f'\n            ascii - 87\n        }) as Field\n    }\n\n    // TODO: Replace with a faster version. \n    // A circuit that uses this function can be slow to compute\n    // (we're doing up to 127 calls to compute the quotient)\n    unconstrained fn unconstrained_div(self: Self, b: U128) -> (U128, U128) {\n        if b == U128::zero() {\n            // Return 0,0 to avoid eternal loop\n            (U128::zero(), U128::zero())\n        } else if self < b {\n            (U128::zero(), self)\n        } else if self == b {\n            (U128::one(), U128::zero())\n        } else {\n            let (q,r) = if b.hi as u64 >= pow63 as u64 {\n                // The result of multiplication by 2 would overflow\n                (U128::zero(), self)\n            } else {\n                self.unconstrained_div(b * U128::from_u64s_le(2, 0))\n            };\n            let q_mul_2 = q * U128::from_u64s_le(2, 0);\n            if r < b {\n                (q_mul_2, r)\n            } else {\n                (q_mul_2 + U128::one(), r - b)\n            }\n        }\n    }\n\n    pub fn from_integer<T>(i: T) -> U128 {\n        let f = crate::as_field(i);\n        // Reject values which would overflow a u128\n        f.assert_max_bit_size(128);\n        let lo = f as u64 as Field;\n        let hi = (f - lo) / pow64;\n        U128 { lo, hi }\n    }\n\n    pub fn to_integer<T>(self) -> T {\n        crate::from_field(self.lo + self.hi * pow64)\n    }\n\n    fn wrapping_mul(self: Self, b: U128) -> U128 {\n        let low = self.lo * b.lo;\n        let lo = low as u64 as Field;\n        let carry = (low - lo) / pow64;\n        let high = self.lo * b.hi + self.hi * b.lo + carry;\n        let hi = high as u64 as Field;\n        U128 { lo, hi }\n    }\n}\n\nimpl Add for U128 {\n    fn add(self: Self, b: U128) -> U128 {\n        let low = self.lo + b.lo;\n        let lo = low as u64 as Field;\n        let carry = (low - lo) / pow64;  \n        let high = self.hi + b.hi + carry;\n        let hi = high as u64 as Field;\n        assert(hi == high, \"attempt to add with overflow\");\n        U128 {\n            lo,\n            hi,\n        }\n    }\n}\n\nimpl Sub for U128 {\n    fn sub(self: Self, b: U128) -> U128 {\n        let low = pow64 + self.lo - b.lo;\n        let lo = low as u64 as Field;\n        let borrow = (low == lo) as Field;\n        let high = self.hi - b.hi - borrow;\n        let hi = high as u64 as Field;\n        assert(hi == high, \"attempt to subtract with underflow\");\n        U128 {\n            lo,\n            hi,\n        }\n    }\n}\n\nimpl Mul for U128 {\n    fn mul(self: Self, b: U128) -> U128 {\n        assert(self.hi*b.hi == 0, \"attempt to multiply with overflow\");\n        let low = self.lo*b.lo;\n        let lo = low as u64 as Field;\n        let carry = (low - lo) / pow64;\n        let high = if crate::field::modulus_num_bits() as u32 > 196 {\n            (self.lo+self.hi)*(b.lo+b.hi) - low + carry\n        } else {\n            self.lo*b.hi + self.hi*b.lo + carry\n        };\n        let hi = high as u64 as Field;\n        assert(hi == high, \"attempt to multiply with overflow\");\n        U128 {\n            lo,\n            hi,\n        }\n    }\n}\n\nimpl Div for U128 {\n    fn div(self: Self, b: U128) -> U128 {\n        unsafe {\n            let (q,r) = self.unconstrained_div(b);\n            let a = b * q + r;\n            assert_eq(self, a);\n            assert(r < b);\n            q\n        }\n    }\n}\n\nimpl Rem for U128 {\n    fn rem(self: Self, b: U128) -> U128 {\n        unsafe {\n            let (q,r) = self.unconstrained_div(b);\n            let a = b * q + r;\n            assert_eq(self, a);\n            assert(r < b);\n            \n            r\n        }\n    }\n}\n\nimpl Eq for U128 {\n    fn eq(self: Self, b: U128) -> bool {\n        (self.lo == b.lo) & (self.hi == b.hi)\n    }\n}\n\nimpl Ord for U128 {\n    fn cmp(self, other: Self) -> Ordering {\n        let hi_ordering = (self.hi as u64).cmp((other.hi as u64));\n        let lo_ordering = (self.lo as u64).cmp((other.lo as u64));\n        \n        if hi_ordering == Ordering::equal() {\n            lo_ordering\n        } else {\n            hi_ordering\n        }\n    }\n}\n\nimpl Not for U128 { \n    fn not(self) -> U128 {\n        U128 {\n            lo: (!(self.lo as u64)) as Field,\n            hi: (!(self.hi as u64)) as Field\n        }\n    }\n}\n\nimpl BitOr for U128 { \n    fn bitor(self, other: U128) -> U128 {\n        U128 {\n            lo: ((self.lo as u64) | (other.lo as u64)) as Field,\n            hi: ((self.hi as u64) | (other.hi as u64)) as Field\n        }\n    }\n}\n\nimpl BitAnd for U128 {\n    fn bitand(self, other: U128) -> U128 { \n        U128 {\n            lo: ((self.lo as u64) & (other.lo as u64)) as Field,\n            hi: ((self.hi as u64) & (other.hi as u64)) as Field\n        }\n    }\n}\n\nimpl BitXor for U128 {\n    fn bitxor(self, other: U128) -> U128 { \n        U128 {\n            lo: ((self.lo as u64) ^ (other.lo as u64)) as Field,\n            hi: ((self.hi as u64) ^ (other.hi as u64)) as Field\n        }\n    }\n}\n\nimpl Shl for U128 { \n    fn shl(self, other: u8) -> U128 { \n        assert(other < 128, \"attempt to shift left with overflow\");\n        let exp_bits: [u1; 7] = (other as Field).to_be_bits();\n\n        let mut r: Field = 2;\n        let mut y: Field = 1;\n        for i in 1..8 {\n            let bit = exp_bits[7-i] as Field;\n            y = bit * (r * y) + (1 - bit) * y;\n            r *= r;\n        }\n        self.wrapping_mul(U128::from_integer(y))\n    } \n}\n\nimpl Shr for U128 { \n    fn shr(self, other: u8) -> U128 { \n        assert(other < 128, \"attempt to shift right with overflow\");\n        let exp_bits: [u1; 7] = (other as Field).to_be_bits();\n\n        let mut r: Field = 2;\n        let mut y: Field = 1;\n        for i in 1..8 {\n            let bit = exp_bits[7-i] as Field;\n            y = bit * (r * y) + (1 - bit) * y;\n            r *= r;\n        }\n        self / U128::from_integer(y)\n    } \n}\n\nmod tests {\n    use crate::uint128::{U128, pow64, pow63};\n\n    #[test]\n    fn test_not(lo: u64, hi: u64) {\n        let num = U128::from_u64s_le(lo, hi);\n        let not_num = num.not();\n\n        assert_eq(not_num.hi, (hi.not() as Field));\n        assert_eq(not_num.lo, (lo.not() as Field));\n\n        let not_not_num = not_num.not();\n        assert_eq(num, not_not_num);\n    }\n    #[test]\n    fn test_construction() {\n        // Check little-endian u64 is inversed with big-endian u64 construction\n        let a = U128::from_u64s_le(2, 1);\n        let b = U128::from_u64s_be(1, 2);\n        assert_eq(a, b);\n        // Check byte construction is equivalent\n        let c = U128::from_le_bytes([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]);\n        let d = U128::from_u64s_le(0x0706050403020100, 0x0f0e0d0c0b0a0908);\n        assert_eq(c, d);\n    }\n    #[test]\n    fn test_byte_decomposition() {\n        let a = U128::from_u64s_le(0x0706050403020100, 0x0f0e0d0c0b0a0908);\n        // Get big-endian and little-endian byte decompostions\n        let le_bytes_a= a.to_le_bytes();\n        let be_bytes_a= a.to_be_bytes();\n\n        // Check equivalence\n        for i in 0..16 {\n            assert_eq(le_bytes_a[i], be_bytes_a[15 - i]);\n        }\n        // Reconstruct U128 from byte decomposition\n        let b= U128::from_le_bytes(le_bytes_a);\n        // Check that it's the same element\n        assert_eq(a, b);\n    }\n    #[test]\n    fn test_hex_constuction() {\n        let a = U128::from_u64s_le(0x1, 0x2);\n        let b = U128::from_hex(\"0x20000000000000001\");\n        assert_eq(a, b);\n\n        let c= U128::from_hex(\"0xffffffffffffffffffffffffffffffff\");\n        let d= U128::from_u64s_le(0xffffffffffffffff, 0xffffffffffffffff);\n        assert_eq(c, d);\n\n        let e= U128::from_hex(\"0x00000000000000000000000000000000\");\n        let f= U128::from_u64s_le(0, 0);\n        assert_eq(e, f);\n    }\n\n    // Ascii decode tests\n\n    #[test]\n    fn test_ascii_decode_correct_range() {\n        // '0'..'9' range\n        for i in 0..10 {\n            let decoded= U128::decode_ascii(48 + i);\n            assert_eq(decoded, i as Field);\n        }\n        // 'A'..'F' range\n        for i in 0..6 {\n            let decoded = U128::decode_ascii(65 + i);\n            assert_eq(decoded, (i + 10) as Field);\n        }\n        // 'a'..'f' range\n        for i in 0..6 {\n            let decoded = U128::decode_ascii(97 + i);\n            assert_eq(decoded, (i + 10) as Field);\n        }\n    }\n\n    #[test(should_fail)]\n    fn test_ascii_decode_range_less_than_48_fails_0() {\n        crate::println(U128::decode_ascii(0));\n    }\n    #[test(should_fail)]\n    fn test_ascii_decode_range_less_than_48_fails_1() {\n        crate::println(U128::decode_ascii(47));\n    }\n\n    #[test(should_fail)]\n    fn test_ascii_decode_range_58_64_fails_0() {\n        let _ = U128::decode_ascii(58);\n    }\n    #[test(should_fail)]\n    fn test_ascii_decode_range_58_64_fails_1() {\n        let _ = U128::decode_ascii(64);\n    }\n    #[test(should_fail)]\n    fn test_ascii_decode_range_71_96_fails_0() {\n        let _ = U128::decode_ascii(71);\n    }\n    #[test(should_fail)]\n    fn test_ascii_decode_range_71_96_fails_1() {\n        let _ = U128::decode_ascii(96);\n    }\n    #[test(should_fail)]\n    fn test_ascii_decode_range_greater_than_102_fails() {\n        let _ = U128::decode_ascii(103);\n    }\n\n    #[test(should_fail)]\n    fn test_ascii_decode_regression() {\n        // This code will actually fail because of ascii_decode,\n        // but in the past it was possible to create a value > (1<<128)\n        let a = U128::from_hex(\"0x~fffffffffffffffffffffffffffffff\");\n        let b:Field= a.to_integer();\n        let c: [u8; 17]= b.to_le_bytes();\n        assert(c[16] != 0);\n    }\n\n    #[test]\n    fn test_unconstrained_div() {\n        // Test the potential overflow case\n        let a= U128::from_u64s_le(0x0, 0xffffffffffffffff);\n        let b= U128::from_u64s_le(0x0, 0xfffffffffffffffe);\n        let c= U128::one();\n        let d= U128::from_u64s_le(0x0, 0x1);\n        unsafe {\n            let (q,r) = a.unconstrained_div(b);\n            assert_eq(q, c);\n            assert_eq(r, d);\n        }\n\n        let a = U128::from_u64s_le(2, 0);\n        let b = U128::one();\n        // Check the case where a is a multiple of b\n        unsafe {\n            let (c, d) = a.unconstrained_div(b);\n            assert_eq((c, d), (a, U128::zero()));\n        }\n\n        // Check where b is a multiple of a\n        unsafe {\n            let (c,d) = b.unconstrained_div(a);\n            assert_eq((c, d), (U128::zero(), b));\n        }\n\n        // Dividing by zero returns 0,0\n        let a = U128::from_u64s_le(0x1, 0x0);\n        let b = U128::zero();\n        unsafe {\n            let (c, d)= a.unconstrained_div(b);\n            assert_eq((c, d), (U128::zero(), U128::zero()));\n        }\n        // Dividing 1<<127 by 1<<127 (special case)\n        let a = U128::from_u64s_le(0x0, pow63 as u64);\n        let b = U128::from_u64s_le(0x0, pow63 as u64);\n        unsafe {\n            let (c, d) = a.unconstrained_div(b);\n            assert_eq((c, d), (U128::one(), U128::zero()));\n        }\n    }\n\n    #[test]\n    fn integer_conversions() {\n        // Maximum\n        let start:Field = 0xffffffffffffffffffffffffffffffff;\n        let a = U128::from_integer(start);\n        let end = a.to_integer();\n        assert_eq(start, end);\n\n        // Minimum\n        let start:Field = 0x0;\n        let a = U128::from_integer(start);\n        let end = a.to_integer();\n        assert_eq(start, end);\n\n        // Low limb\n        let start:Field = 0xffffffffffffffff;\n        let a = U128::from_integer(start);\n        let end = a.to_integer();\n        assert_eq(start, end);\n\n        // High limb\n        let start:Field = 0xffffffffffffffff0000000000000000;\n        let a = U128::from_integer(start);\n        let end = a.to_integer();\n        assert_eq(start, end);\n    }\n\n    #[test]\n    fn integer_conversions_fuzz(lo: u64, hi: u64) {\n        let start: Field = (lo as Field) + pow64 * (hi as Field);\n        let a = U128::from_integer(start);\n        let end = a.to_integer();\n        assert_eq(start, end);\n    }\n\n    #[test]\n    fn test_wrapping_mul() {\n        // 1*0==0\n        assert_eq(U128::zero(), U128::zero().wrapping_mul(U128::one()));\n\n        // 0*1==0\n        assert_eq(U128::zero(), U128::one().wrapping_mul(U128::zero()));\n\n        // 1*1==1\n        assert_eq(U128::one(), U128::one().wrapping_mul(U128::one()));\n\n        // 0 * ( 1 << 64 ) ==  0\n        assert_eq(U128::zero(), U128::zero().wrapping_mul(U128::from_u64s_le(0, 1)));\n\n        // ( 1 << 64 ) * 0 == 0\n        assert_eq(U128::zero(), U128::from_u64s_le(0, 1).wrapping_mul(U128::zero()));\n\n        // 1 * ( 1 << 64 ) == 1 << 64\n        assert_eq(U128::from_u64s_le(0, 1), U128::from_u64s_le(0, 1).wrapping_mul(U128::one()));\n\n        // ( 1 << 64 ) * 1 == 1 << 64\n        assert_eq(U128::from_u64s_le(0, 1), U128::one().wrapping_mul(U128::from_u64s_le(0, 1)));\n\n        // ( 1 << 64 ) * ( 1 << 64 ) == 1 << 64\n        assert_eq(U128::zero(), U128::from_u64s_le(0, 1).wrapping_mul(U128::from_u64s_le(0, 1)));\n        // -1 * -1 == 1\n        assert_eq(\n            U128::one(), U128::from_u64s_le(0xffffffffffffffff, 0xffffffffffffffff).wrapping_mul(U128::from_u64s_le(0xffffffffffffffff, 0xffffffffffffffff))\n        );\n    }\n}\n"},"67":{"path":"/Users/tiagofneto/Documents/Projects/startup-company-monorepo/contracts/src/main.nr","source":"mod types;\n\ncontract CompanyRegistry {\n    use dep::aztec::prelude::{Map, PublicMutable};\n    use dep::compressed_string::FieldCompressedString;\n    use crate::types::Company;\n\n    #[aztec(storage)]\n    struct Storage {\n        companies: Map<U128, PublicMutable<Company>>,\n        company_count: PublicMutable<U128>\n    }\n\n    #[aztec(public)]\n    fn create_company(name: FieldCompressedString, email: FieldCompressedString, director: FieldCompressedString, total_shares: U128) {\n        let id = storage.company_count.read().add(U128::from_integer(1));\n\n        let company = Company {\n            name: name,\n            email: email,\n            director: director,\n            total_shares: total_shares\n        };\n\n        storage.companies.at(id).write(company);\n        storage.company_count.write(id);\n    }\n}\n"},"68":{"path":"/Users/tiagofneto/Documents/Projects/startup-company-monorepo/contracts/src/types.nr","source":"use dep::compressed_string::FieldCompressedString;\nuse dep::protocol_types::traits::{Serialize, Deserialize};\n\nstruct Company {\n    name: FieldCompressedString,\n    email: FieldCompressedString,\n    director: FieldCompressedString,\n    total_shares: U128\n}\n\nimpl Serialize<4> for Company {\n    fn serialize(self) -> [Field; 4] {\n        [self.name.serialize()[0], self.email.serialize()[0], self.director.serialize()[0], self.total_shares.serialize()[0]]\n    }\n}\n\nimpl Deserialize<4> for Company {\n    fn deserialize(fields: [Field; 4]) -> Self {\n        Self { \n            name: FieldCompressedString::from_field(fields[0]), \n            email: FieldCompressedString::from_field(fields[1]), \n            director: FieldCompressedString::from_field(fields[2]), \n            total_shares: U128::from_field(fields[3])\n        }\n    }\n}\n\n"},"79":{"path":"/Users/tiagofneto/nargo/github.com/AztecProtocol/aztec-packages/aztec-packages-v0.54.0/noir-projects/aztec-nr/aztec/src/context/public_context.nr","source":"use crate::hash::{compute_secret_hash, compute_message_hash, compute_message_nullifier};\nuse dep::protocol_types::address::{AztecAddress, EthAddress};\nuse dep::protocol_types::constants::MAX_FIELD_VALUE;\nuse dep::protocol_types::traits::{Serialize, Deserialize, Empty};\nuse dep::protocol_types::abis::function_selector::FunctionSelector;\nuse crate::context::inputs::public_context_inputs::PublicContextInputs;\nuse crate::context::gas::GasOpts;\nuse crate::hash::ArgsHasher;\n\nstruct PublicContext {\n    inputs: PublicContextInputs,\n    args_hash: Option<Field>\n}\n\nimpl PublicContext {\n    pub fn new(inputs: PublicContextInputs) -> Self {\n        PublicContext { inputs, args_hash: Option::none() }\n    }\n\n    pub fn emit_unencrypted_log<T, let N: u32>(_self: &mut Self, log: T) where T: Serialize<N> {\n        emit_unencrypted_log(Serialize::serialize(log).as_slice());\n    }\n\n    pub fn note_hash_exists(_self: Self, note_hash: Field, leaf_index: Field) -> bool {\n        note_hash_exists(note_hash, leaf_index) == 1\n    }\n\n    pub fn l1_to_l2_msg_exists(_self: Self, msg_hash: Field, msg_leaf_index: Field) -> bool {\n        l1_to_l2_msg_exists(msg_hash, msg_leaf_index) == 1\n    }\n\n    fn nullifier_exists(_self: Self, unsiloed_nullifier: Field, address: AztecAddress) -> bool {\n        nullifier_exists(unsiloed_nullifier, address.to_field()) == 1\n    }\n\n    fn consume_l1_to_l2_message(\n        &mut self,\n        content: Field,\n        secret: Field,\n        sender: EthAddress,\n        leaf_index: Field\n    ) {\n        let secret_hash = compute_secret_hash(secret);\n        let message_hash = compute_message_hash(\n            sender,\n            self.chain_id(),\n            /*recipient=*/ self.this_address(),\n            self.version(),\n            content,\n            secret_hash\n        );\n        let nullifier = compute_message_nullifier(message_hash, secret, leaf_index);\n\n        assert(\n            !self.nullifier_exists(nullifier, self.this_address()), \"L1-to-L2 message is already nullified\"\n        );\n        assert(\n            self.l1_to_l2_msg_exists(message_hash, leaf_index), \"Tried to consume nonexistent L1-to-L2 message\"\n        );\n\n        self.push_nullifier(nullifier);\n    }\n\n    fn message_portal(_self: &mut Self, recipient: EthAddress, content: Field) {\n        send_l2_to_l1_msg(recipient, content);\n    }\n\n    fn call_public_function<let RETURNS_COUNT: u32>(\n        _self: &mut Self,\n        contract_address: AztecAddress,\n        function_selector: FunctionSelector,\n        args: [Field],\n        gas_opts: GasOpts\n    ) -> FunctionReturns<RETURNS_COUNT> {\n        let results = call(\n            gas_for_call(gas_opts),\n            contract_address,\n            args,\n            function_selector.to_field()\n        );\n        let data_to_return: [Field; RETURNS_COUNT] = results.0;\n        let success: u8 = results.1;\n        assert(success == 1, \"Nested call failed!\");\n\n        FunctionReturns::new(data_to_return)\n    }\n\n    fn static_call_public_function<let RETURNS_COUNT: u32>(\n        _self: &mut Self,\n        contract_address: AztecAddress,\n        function_selector: FunctionSelector,\n        args: [Field],\n        gas_opts: GasOpts\n    ) -> FunctionReturns<RETURNS_COUNT> {\n        let (data_to_return, success): ([Field; RETURNS_COUNT], u8) = call_static(\n            gas_for_call(gas_opts),\n            contract_address,\n            args,\n            function_selector.to_field()\n        );\n\n        assert(success == 1, \"Nested static call failed!\");\n        FunctionReturns::new(data_to_return)\n    }\n\n    fn delegate_call_public_function<let RETURNS_COUNT: u32>(\n        _self: &mut Self,\n        _contract_address: AztecAddress,\n        _function_selector: FunctionSelector,\n        _args: [Field]\n    ) -> FunctionReturns<RETURNS_COUNT> {\n        assert(false, \"'delegate_call_public_function' not implemented!\");\n        FunctionReturns::new([0; RETURNS_COUNT])\n    }\n\n    fn push_note_hash(_self: &mut Self, note_hash: Field) {\n        emit_note_hash(note_hash);\n    }\n    fn push_nullifier(_self: &mut Self, nullifier: Field) {\n        emit_nullifier(nullifier);\n    }\n\n    fn this_address(_self: Self) -> AztecAddress {\n        address()\n    }\n    pub fn storage_address(_self: Self) -> AztecAddress {\n        storage_address()\n    }\n    fn msg_sender(_self: Self) -> AztecAddress {\n        sender()\n    }\n    fn selector(_self: Self) -> FunctionSelector {\n        FunctionSelector::from_u32(function_selector())\n    }\n    fn get_args_hash(mut self) -> Field {\n        if !self.args_hash.is_some() {\n            let mut hasher = ArgsHasher::new();\n\n            // TODO: this should be replaced with the compile-time calldata size.\n            for i in 0..self.inputs.calldata_length as u32 {\n                let argn: [Field; 1] = calldata_copy((2 + i) as u32, 1);\n                hasher.add(argn[0]);\n            }\n\n            self.args_hash = Option::some(hasher.hash());\n        }\n\n        self.args_hash.unwrap()\n    }\n    fn transaction_fee(_self: Self) -> Field {\n        transaction_fee()\n    }\n\n    fn chain_id(_self: Self) -> Field {\n        chain_id()\n    }\n    fn version(_self: Self) -> Field {\n        version()\n    }\n    fn block_number(_self: Self) -> Field {\n        block_number()\n    }\n    fn timestamp(_self: Self) -> u64 {\n        timestamp()\n    }\n    pub fn fee_per_l2_gas(_self: Self) -> Field {\n        fee_per_l2_gas()\n    }\n    pub fn fee_per_da_gas(_self: Self) -> Field {\n        fee_per_da_gas()\n    }\n\n    fn l2_gas_left(_self: Self) -> Field {\n        l2_gas_left()\n    }\n    fn da_gas_left(_self: Self) -> Field {\n        da_gas_left()\n    }\n\n    fn raw_storage_read<let N: u32>(_self: Self, storage_slot: Field) -> [Field; N] {\n        let mut out = [0; N];\n        for i in 0..N {\n            out[i] = storage_read(storage_slot + i as Field);\n        }\n        out\n    }\n\n    fn storage_read<T, let N: u32>(self, storage_slot: Field) -> T where T: Deserialize<N> {\n        T::deserialize(self.raw_storage_read(storage_slot))\n    }\n\n    fn raw_storage_write<let N: u32>(_self: Self, storage_slot: Field, values: [Field; N]) {\n        for i in 0..N {\n            storage_write(storage_slot + i as Field, values[i]);\n        }\n    }\n\n    fn storage_write<T, let N: u32>(self, storage_slot: Field, value: T) where T: Serialize<N> {\n        self.raw_storage_write(storage_slot, value.serialize());\n    }\n}\n\n// Helper functions\nfn gas_for_call(user_gas: GasOpts) -> [Field; 2] {\n    // It's ok to use the max possible gas here, because the gas will be\n    // capped by the gas left in the (STATIC)CALL instruction.\n    [\n        user_gas.l2_gas.unwrap_or(MAX_FIELD_VALUE),\n        user_gas.da_gas.unwrap_or(MAX_FIELD_VALUE)\n    ]\n}\n\n// Unconstrained opcode wrappers (do not use directly).\n// TODO(https://github.com/AztecProtocol/aztec-packages/issues/6420): reconsider.\nunconstrained fn address() -> AztecAddress {\n    address_opcode()\n}\nunconstrained fn storage_address() -> AztecAddress {\n    storage_address_opcode()\n}\nunconstrained fn sender() -> AztecAddress {\n    sender_opcode()\n}\nunconstrained fn portal() -> EthAddress {\n    portal_opcode()\n}\nunconstrained fn function_selector() -> u32 {\n    function_selector_opcode()\n}\nunconstrained fn transaction_fee() -> Field {\n    transaction_fee_opcode()\n}\nunconstrained fn chain_id() -> Field {\n    chain_id_opcode()\n}\nunconstrained fn version() -> Field {\n    version_opcode()\n}\nunconstrained fn block_number() -> Field {\n    block_number_opcode()\n}\nunconstrained fn timestamp() -> u64 {\n    timestamp_opcode()\n}\nunconstrained fn fee_per_l2_gas() -> Field {\n    fee_per_l2_gas_opcode()\n}\nunconstrained fn fee_per_da_gas() -> Field {\n    fee_per_da_gas_opcode()\n}\nunconstrained fn l2_gas_left() -> Field {\n    l2_gas_left_opcode()\n}\nunconstrained fn da_gas_left() -> Field {\n    da_gas_left_opcode()\n}\nunconstrained fn note_hash_exists(note_hash: Field, leaf_index: Field) -> u8 {\n    note_hash_exists_opcode(note_hash, leaf_index)\n}\nunconstrained fn emit_note_hash(note_hash: Field) {\n    emit_note_hash_opcode(note_hash)\n}\nunconstrained fn nullifier_exists(nullifier: Field, address: Field) -> u8 {\n    nullifier_exists_opcode(nullifier, address)\n}\nunconstrained fn emit_nullifier(nullifier: Field) {\n    emit_nullifier_opcode(nullifier)\n}\nunconstrained fn emit_unencrypted_log(message: [Field]) {\n    emit_unencrypted_log_opcode(message)\n}\nunconstrained fn l1_to_l2_msg_exists(msg_hash: Field, msg_leaf_index: Field) -> u8 {\n    l1_to_l2_msg_exists_opcode(msg_hash, msg_leaf_index)\n}\nunconstrained fn send_l2_to_l1_msg(recipient: EthAddress, content: Field) {\n    send_l2_to_l1_msg_opcode(recipient, content)\n}\nunconstrained fn call<let RET_SIZE: u32>(\n    gas: [Field; 2],\n    address: AztecAddress,\n    args: [Field],\n    function_selector: Field\n) -> ([Field; RET_SIZE], u8) {\n    call_opcode(gas, address, args, function_selector)\n}\nunconstrained fn call_static<let RET_SIZE: u32>(\n    gas: [Field; 2],\n    address: AztecAddress,\n    args: [Field],\n    function_selector: Field\n) -> ([Field; RET_SIZE], u8) {\n    call_static_opcode(gas, address, args, function_selector)\n}\n\nunconstrained fn calldata_copy<let N: u32>(cdoffset: u32, copy_size: u32) -> [Field; N] {\n    calldata_copy_opcode(cdoffset, copy_size)\n}\n\nunconstrained fn storage_read(storage_slot: Field) -> Field {\n    storage_read_opcode(storage_slot)\n}\n\nunconstrained fn storage_write(storage_slot: Field, value: Field) {\n    storage_write_opcode(storage_slot, value);\n}\n\nimpl Empty for PublicContext {\n    fn empty() -> Self {\n        PublicContext::new(PublicContextInputs::empty())\n    }\n}\n\n// AVM oracles (opcodes) follow, do not use directly.\n#[oracle(avmOpcodeAddress)]\nunconstrained fn address_opcode() -> AztecAddress {}\n\n#[oracle(avmOpcodeStorageAddress)]\nunconstrained fn storage_address_opcode() -> AztecAddress {}\n\n#[oracle(avmOpcodeSender)]\nunconstrained fn sender_opcode() -> AztecAddress {}\n\n#[oracle(avmOpcodePortal)]\nunconstrained fn portal_opcode() -> EthAddress {}\n\n#[oracle(avmOpcodeFunctionSelector)]\nunconstrained fn function_selector_opcode() -> u32 {}\n\n#[oracle(avmOpcodeTransactionFee)]\nunconstrained fn transaction_fee_opcode() -> Field {}\n\n#[oracle(avmOpcodeChainId)]\nunconstrained fn chain_id_opcode() -> Field {}\n\n#[oracle(avmOpcodeVersion)]\nunconstrained fn version_opcode() -> Field {}\n\n#[oracle(avmOpcodeBlockNumber)]\nunconstrained fn block_number_opcode() -> Field {}\n\n#[oracle(avmOpcodeTimestamp)]\nunconstrained fn timestamp_opcode() -> u64 {}\n\n#[oracle(avmOpcodeFeePerL2Gas)]\nunconstrained fn fee_per_l2_gas_opcode() -> Field {}\n\n#[oracle(avmOpcodeFeePerDaGas)]\nunconstrained fn fee_per_da_gas_opcode() -> Field {}\n\n#[oracle(avmOpcodeL2GasLeft)]\nunconstrained fn l2_gas_left_opcode() -> Field {}\n\n#[oracle(avmOpcodeDaGasLeft)]\nunconstrained fn da_gas_left_opcode() -> Field {}\n\n#[oracle(avmOpcodeNoteHashExists)]\nunconstrained fn note_hash_exists_opcode(note_hash: Field, leaf_index: Field) -> u8 {}\n\n#[oracle(avmOpcodeEmitNoteHash)]\nunconstrained fn emit_note_hash_opcode(note_hash: Field) {}\n\n#[oracle(avmOpcodeNullifierExists)]\nunconstrained fn nullifier_exists_opcode(nullifier: Field, address: Field) -> u8 {}\n\n#[oracle(avmOpcodeEmitNullifier)]\nunconstrained fn emit_nullifier_opcode(nullifier: Field) {}\n\n#[oracle(avmOpcodeEmitUnencryptedLog)]\nunconstrained fn emit_unencrypted_log_opcode(message: [Field]) {}\n\n#[oracle(avmOpcodeL1ToL2MsgExists)]\nunconstrained fn l1_to_l2_msg_exists_opcode(msg_hash: Field, msg_leaf_index: Field) -> u8 {}\n\n#[oracle(avmOpcodeSendL2ToL1Msg)]\nunconstrained fn send_l2_to_l1_msg_opcode(recipient: EthAddress, content: Field) {}\n\n#[oracle(avmOpcodeCalldataCopy)]\nunconstrained fn calldata_copy_opcode<let N: u32>(cdoffset: u32, copy_size: u32) -> [Field; N] {}\n\n#[oracle(avmOpcodeCall)]\nunconstrained fn call_opcode<let RET_SIZE: u32>(\n    gas: [Field; 2], // gas allocation: [l2_gas, da_gas]\n    address: AztecAddress,\n    args: [Field],\n    // TODO(5110): consider passing in calldata directly\n    function_selector: Field\n) -> ([Field; RET_SIZE], u8) {}\n//    ^ return data      ^ success\n\n#[oracle(avmOpcodeStaticCall)]\nunconstrained fn call_static_opcode<let RET_SIZE: u32>(\n    gas: [Field; 2], // gas allocation: [l2_gas, da_gas]\n    address: AztecAddress,\n    args: [Field],\n    // TODO(5110): consider passing in calldata directly\n    function_selector: Field\n) -> ([Field; RET_SIZE], u8) {}\n//    ^ return data      ^ success\n\n#[oracle(avmOpcodeStorageRead)]\nunconstrained fn storage_read_opcode(storage_slot: Field) -> Field {}\n\n#[oracle(avmOpcodeStorageWrite)]\nunconstrained fn storage_write_opcode(storage_slot: Field, value: Field) {}\n\nstruct FunctionReturns<let N: u32> {\n    values: [Field; N]\n}\n\nimpl<let N: u32> FunctionReturns<N> {\n    pub fn new(values: [Field; N]) -> FunctionReturns<N> {\n        FunctionReturns { values }\n    }\n\n    pub fn raw(self) -> [Field; N] {\n        self.values\n    }\n\n    pub fn deserialize_into<T>(self) -> T where T: Deserialize<N> {\n        Deserialize::deserialize(self.raw())\n    }\n}\n\nimpl FunctionReturns<0> {\n    pub fn assert_empty(self) {\n        assert(self.values.len() == 0);\n    }\n}\n"}}}